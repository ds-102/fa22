{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab03.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3:  Bayesian Estimation in Hierarchical Graphical Models\n",
    "Welcome to the third Data 102 lab! \n",
    "\n",
    "The goal of this lab is to go over Bayesian Estimation and provide an introduction to Hierarchial Graphical Models.\n",
    "\n",
    "The code and responses you need to fill in are represented by `...`. There is additional documentation for each part as you go along. \n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "## Gradescope Submission\n",
    "To submit the lab: \n",
    "1. Navigate to Kernel > Restart & Run All. Ensure that all public test cases pass locally. \n",
    "2. Save your notebook under File > Save and Checkpoint. If you do not save your notebook, then you might run into issues with the downloaded .zip file.\n",
    "3. Run the very last cell, which generates a .zip file for you to download to your local machine. Click the “here” button to download the .zip file. You may receive an error that the .zip file was unable to be created because there was an issue with PDF generation. You need to ensure that you’ve answered all of the questions that require a manual response.\n",
    "4. If your work downloads as several independent files rather than as a .zip, you are likely using Safari on a Mac. Follow these instructions to make sure you can download your work as a zip: https://macreports.com/how-to-download-zip-files-without-unzipping/\n",
    "5. Upload this .zip to the correct assignment on Gradescope. After submitting, the autograder built-in to the Gradescope assignment will tell you which public test cases you’ve passed and failed. There are no hidden test cases.\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Thursday, September 22, 2022 at 11:59 PM. PT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import beta, binom\n",
    "import itertools\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "\n",
    "import hashlib\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def get_hash(num, significance = 4):\n",
    "    num = round(num, significance)\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()\n",
    "\n",
    "import pymc3 as pm\n",
    "import logging\n",
    "logger = logging.getLogger('pymc3')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Beta-Binomial Graphical Model\n",
    "\n",
    "In this question we will look at the COVID modeling example. Here's the summary of what you need to know:\n",
    "\n",
    "In this problem we are trying to estimate the COVID infection risk in households. To do that we curate a list of K studies. Each study has an associated pair $(N_i, X_i)$ where $N_i$ denotes the number of susceptible individuals considered and $X_i$ is the number of them that became infected. In our modeling assumptions we assume that each susceptible person gets infected with probability $\\theta_i$. In epidemiology, this quantity is known as Secondary Attack Rate, or SAR for short.\n",
    "\n",
    "We're trying to do two things: \n",
    "1. We want to *combine* the information from all the studies, so we can get a better estimate of SAR than we would with any individual study on its own. \n",
    "2. We want to understand why the studies got different results: specifically, we'd like to figure out the regions with the *lowest* SAR, so that we can investigate what contributed to their relative success. In the other direction, we want to know which regions had the *highest* SAR, since they're likely the ones most urgently in need of intervention measures to help slow the spread.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out a dataset \n",
    "study_df = pd.read_csv(\"study_df.csv\", header=0)\n",
    "study_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.a Compute the trivial estimate of SAR\n",
    "\n",
    "\n",
    "The most straightforward way to estimate the probability of infection (SAR) is to divide the number of infected cases by the number of susceptible cases. \n",
    "\n",
    "Compute this quantity in the cell below.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the function\n",
    "def trivial_theta_estimate(N_value, X_value):\n",
    "    \"\"\"\n",
    "    Computes the trivial estimate of the Secondary Attack Rate\n",
    "    \n",
    "    Inputs:\n",
    "        N_value : int, number of susceptible individuals\n",
    "        X_value : int, number of infected individuals\n",
    "        \n",
    "    Output:\n",
    "        theta_est : float, estimate of probability of infection (SAR)\n",
    "    \"\"\"\n",
    "    theta_est = ...\n",
    "    return theta_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\n",
    "study_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)\n",
    "study_df.sort_values('Trivial estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trivial estimates suggest that both minimum and maximum probabilities of infection correspond to small studies.**\n",
    "\n",
    "|      | Min     | Max     |\n",
    "|------|---------|---------|\n",
    "| Name | Study 1 | Study 2 |\n",
    "| X    | 2       | 8       | \n",
    "| N    | 11      | 12      |\n",
    "|$\\theta$| 0.18  | 0.50    |\n",
    "\n",
    "\n",
    "Intuitively, we probably shouldn't be making policy decision based on such small studies alone, especially when this dataset has other studies with tens or even hundreds of people. We would like to balance between strong evidence from the small studies and high confidence in estimates from larger studies.\n",
    "\n",
    "Bayesian inference provides a flexible framework to balance our a priori beliefs with new evidence. Consider the following graphical model:\n",
    "\n",
    "\n",
    "![](model.png)\n",
    "\n",
    "\n",
    "The circles represent random variables, and shaded circles represent observed random variables. The diamond at the top represents fixed, unknown parameters . You'll also see people draw dots or squares for these: there isn't really one consistent notation.\n",
    "\n",
    "Here are a few important quantities in Bayesian inference. This lingo will be used at length in this course and in anything you'll learn in the future about Bayesian inference, so make sure you get familiar with it.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Joint Density / Joint Distribution:\n",
    "The structure of the graphical model specified the full joint density of the parameters and data in the model. For this example the join density is:\n",
    "$$p(\\theta_1, \\theta_2, \\ldots, \\theta_K, X_1, \\ldots, X_K) = \\prod_{\\text{vertex $V$ in graph}}p(V|\\text{parent of $V$}) = \\prod_{i=1}^K \\underbrace{p(\\theta_i|\\alpha, \\beta)}_{\\text{prior of $\\theta_i$}} \\prod_{i=1}^K \\underbrace{p(X_i|\\theta_i)}_{\\text{likelihood of data $X_i$}}$$\n",
    "\n",
    "The factorization of the joint density into products of priors and likelihoods is the key feature of Hierarchical Models. It allows to take a complex $2K$-dimensional joint probability and factorize it into products of 1-dimensional probabilities. This factorization is useful because it lets us simplify the distribution and control the amount of computation we have to do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Prior:  $\\theta_i \\sim Beta(\\alpha, \\beta)$\n",
    "\n",
    "We have the prior distribution:\n",
    "\n",
    "\\begin{align}\n",
    "p(\\theta_i) \n",
    "    &= \\theta_i^{\\alpha-1}(1-\\theta_i)^{\\beta-1} \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\\\\n",
    "    &\\propto_{\\theta_i}\\theta_i^{\\alpha-1}(1-\\theta_i)^{\\beta-1}\n",
    "\\end{align}\n",
    "\n",
    "where $\\Gamma$ is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function). Since $\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}$ does not depend on the value of $\\theta$. It is a scaling factor that ensures that $p(\\theta_i)$ is a valid probability function. This leads to a common notation in practice: $p(\\theta_i)\\propto_{\\theta_i}\\theta_i^{\\alpha-1}(1-\\theta_i)^{\\beta-1}$. The symbol $\\propto_{\\theta_i}$ means proportional in $\\theta_i$. This is a little more explicit than the $\\propto$ notation that you usually see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood: $X_i|\\theta \\sim Binomial(N_i, \\theta_i)$\n",
    "\n",
    "We'll use the notation $p(X_i|\\theta)$ for the likelihood function, which represents our belief about the distribution of the data if we know what the parameter $\\theta$ is (in other words, if we condition on $\\theta$).\n",
    "$$p(X_i|\\theta_i) = \\binom{N_i}{X_i} \\theta_i^{X_i}(1-\\theta_i)^{N_i - X_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal: Unconditional distribution of $X_i$:\n",
    "\n",
    "\\begin{align}\n",
    "p(X_i)\n",
    "    &= \\int_{\\theta_i} \\overbrace{p(X_i, \\theta_i)}^{\\text{joint distribution}} \\\\\n",
    "    &= \\int_0^1 \\underbrace{p(X_i|\\theta_i)}_{\\text{likelihood}} \\,\\underbrace{p(\\theta_i)}_{\\text{prior}} \\,d\\theta_i\n",
    "\\end{align}\n",
    "\n",
    "This is the marginal distribution over the data: we can plug in a particular set of $X_i$ values and get out the probability that our model assigns to those values, averaged over all possible values of $\\theta$.\n",
    "\n",
    "When formulating a model, we usually choose the prior and the likelihood based on what we know about the problem. This means that computing this marginal distribution over $X_i$ requires *marginalizing* over the parameter $\\theta$: that involves either a summation or an integral (in this case it's an integral because $\\theta$ is continuous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior: $\\theta_i|X_i$\n",
    "The goal of many estimation problems is to obtain the posterior distribution of the parameter of interest $\\theta_i$ conditioned on the data $X_i$.\n",
    "\n",
    "\\begin{align}\n",
    "p(\\theta_i|X_i) &= \\frac{p(X_i|\\theta_i)p(\\theta_i)}{p(X_i)} \\quad \\text{(by Bayes Rule)}\\\\\n",
    "&\\propto_{\\theta} p(X_i|\\theta_i)p(\\theta_i) \\quad \\text{(the data marginal $p(X_i)$ does not depend on $\\theta$)}\\\\\n",
    "&\\propto_{\\theta}  \\underbrace{\\theta_i^{X_i}(1-\\theta_i)^{N_i - X_i}}_{\\text{likelihood}} \\underbrace{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}_{\\text{prior}}\\\\\n",
    "&\\propto_{\\theta}\\theta_i^{\\alpha + X_i - 1}(1-\\theta_i)^{\\beta + N_i - X_i - 1} \\quad \\text{unnormalized Beta density}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence $\\theta_i|X_i \\sim Beta(\\alpha + X_i, \\beta + N_i - X_i)$\n",
    "\n",
    "\n",
    "The fact that the posterior probability comes from the same distribution family as the prior is known as *conjugacy*. It is a very useful property because it allows us to compute the posteriors in closed form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.b 'When specifying a Bayesian model, we use our domain knowledge to establish certain distributions, and then we use computation to find other ones. Which of the following do we establish using our domain knowledge? Pick all that apply.\n",
    "\n",
    "(a) Prior\n",
    "\n",
    "(b) Likelihood\n",
    "\n",
    "(c) Marginal distribution of the data\n",
    "\n",
    "(d) Posterior \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 1.c Examine the prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta(alpha_value, beta_value):\n",
    "    x = np.arange(0, 1.01, 0.01)\n",
    "    y = beta.pdf(x, alpha_value, beta_value)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(r'$\\theta_i$')\n",
    "    plt.ylabel(r'$p(\\theta_i)$')\n",
    "    plt.title(r'Beta distribution with parameters $\\alpha$ and $\\beta$')\n",
    "    plt.ylim(0, 10)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.c (i) Fix `alpha_value = 5`, and experiment with different values of `beta_value`. Write 1 sentence of your observations.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1ci\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.c (ii) Fix `beta_value = 5`, and experiment with different values of `alpha_value`. Write 1 sentence of your observations.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1cii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.c (iii) Set `alpha_value = beta_value = 1`, increase their value such that `alpha_value=beta_value`. Write 1 sentence of your observations.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1ciii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 1.d Compute Posterior Mean Estimates for SAR\n",
    "In Problem 1 of Discussion 3 we showed that the **posterior mean** minimizes the **Bayes Risk** for the **Squared Error Loss**.\n",
    "\n",
    "#### In the cell below write a function that computes the posterior mean corresponding to $\\theta_i|X_i$.\n",
    "\n",
    "*Hint: If you need to look up facts about certain well-known distributions, you can always (a) go to textbooks from classes you've taken before, (b) look on Wikipedia, or (c) do a simple web search.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def posterior_mean_estimate(N_value, X_value, alpha_value, beta_value):\n",
    "    \"\"\"\n",
    "    Computes the posterior E[theta_i|X_i] when we consider a prior theta_i ~ Beta(alpha, beta)\n",
    "    \n",
    "    Inputs: \n",
    "        N_value : int, total number of susceptible individuals\n",
    "        X_value : int, number of individuals that became infected\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "    \"\"\"\n",
    "    posterior_mean = ...\n",
    "    return posterior_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.e Examine the posterior mean estimate\n",
    "\n",
    "Let's assume that from domain knowledge, we think that the probability of infection (SAR) is close to $\\frac{1}{3}$. We pick a prior distribution for $\\theta_i$ that has mean $\\frac{1}{3}$. Any distribution of the form $\\theta_i \\sim Beta(k, 2k)$ has this property. The value of $k$ determines the 'strength' of the prior. Low values of $k$  correspond to 'flatter' priors, while larger values of $k$ correspond to 'peakier' priors. Play with the sliders in **1.b** to convince yourself.\n",
    "\n",
    "**Examine the plotting function below and answer the qualitative questions in the next cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify: Examine the code\n",
    "def plot_thetas(k):\n",
    "    \n",
    "    study_df[\"bayesian_theta\"] = study_df.apply(\n",
    "        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n",
    "        axis=1\n",
    "    )\n",
    "    study_df[\"trivial_theta\"] = study_df.apply(\n",
    "        lambda row: trivial_theta_estimate(row['N'], row['X']), \n",
    "        axis=1\n",
    "    )\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    graph = sns.scatterplot(\n",
    "        x=\"trivial_theta\", y=\"bayesian_theta\", \n",
    "        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x='trivial_theta', y='trivial_theta', \n",
    "        data= study_df, ls=\"--\", color='black', lw=1\n",
    "    )\n",
    "    plt.ylim(0.16, 0.52)\n",
    "    graph.axhline(\n",
    "        1/3, color='black', \n",
    "        label = \"$\\frac{1}{3}$ Prior Expectation\"\n",
    "    )\n",
    "    plt.xlabel('Trivial Estimate')\n",
    "    plt.ylabel('Posterior Mean Estimate')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    x = np.arange(0,1.01,0.01)\n",
    "    y = beta.pdf(x, k, 2*k)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(r'$\\theta_i$')\n",
    "    plt.ylabel(r'$p(\\theta_i)$')\n",
    "    plt.title(rf'Prior: $Beta(\\alpha={k}, \\beta={2*k})$')\n",
    "    plt.ylim(0, 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above the horizontal dashed line represents the prior mean estimate $\\mathbb{E}[\\theta_i] = \\frac{k}{k+2k} = 1/3$. The diagonal solid line marks $x=y$. Each data-point corresponds to a study, the size of the marker denotes the number of susceptible individuals in each study. Such that larger markers correspond to larger studies.\n",
    "\n",
    "**Answer the following questions with 1-2 sentences each.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.e (i) Set $k=0$, what do you notice about the data points? Increase steadily the value of $k$. What happens with the points above the solid horizontal line? What about the points below it?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1ei\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.e (ii) As you increase $k$, which points move faster, larger or slower ones? How can you explain this?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1eii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.e (iii) Imagine that we let $k\\to \\infty$. How do you think the two graphs above will look in the limit $k\\to \\infty$? \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1eiii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1.e (iv) Fill in the blank in this sentence with either \"small\" or \"large\", and explain your answer: \n",
    "\n",
    "*If we're very sure that the true SAR is close to $\\frac{1}{3}$, we should choose a _______ value of $k$.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1eiv\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 2: Computational Approximate Inference\n",
    "\n",
    "In the previous question we looked at a Beta-Binomial Graphical model. We took advantage of the conjugacy properties of the model and were able to compute closed form solutions for the posterior mean estimates.\n",
    "\n",
    "However, as we introduce more complexity to the model, the conjugacy property quickly breaks and we have to resort to approximate inference. In this class, we'll focus primarily on *sampling* for approximate inference: this will be the topic of the next few lectures and next week's labs. In sampling-based approaches, we don't even try to get the exact posterior: instead, we generate a bunch of samples from it, and use those to approximate the distribution.\n",
    "\n",
    "In this question you will get a taste for probabilistic programming using `PyMC3`. Spend some time perusing the [documentation](https://docs.pymc.io/), but don't worry if there are parts that don't make sense yet. The Quickstart guide is a useful starting point. \n",
    "\n",
    "We'll be using PyMC3 to run an algorithm called Markov Chain Monte Carlo (MCMC), which you'll learn about this week. We'll start by using the same model from Q.1, and compare the results from MCMC with the exact solutions we calculated above. Then, we'll add an extra parameter to the model and make things more complex: even though we can no longer compute our posterior in closed form, MCMC will still generate samples that we can use to estimate each $\\theta_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy model so that one-time initialization\n",
    "# happens while you're reading over the code in the next cell.\n",
    "\n",
    "# Note: this and the following cells may take a while to run\n",
    "\n",
    "# You can ignore the output of this cell.\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dummy = pm.Beta('dummy', alpha=1, beta=1)\n",
    "    pm.sample(1, return_inferencedata=False, progressbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2.a: Building and sampling from a PyMC3 model\n",
    "\n",
    "The code in the cell below defines the model from Question 1 using PyMC3. Define the theta and X nodes according to the instructions. The PyMC3 website has documentation for defining variables according to the Beta and Binomial distribution. If you have no idea how to proceed, the PyMC3 Quickstart guide or the [notes from lecture 7](http://data102.datahub.berkeley.edu/hub/user-redirect/git-sync?repo=https://github.com/ds-102/fa22&subPath=lecture/lecture07/lecture07.ipynb) are great places to start.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify: Spend some time examining the code\n",
    "def approximate_inference_MCMC(\n",
    "    alpha_value, beta_value, study_df = study_df\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates and generates samples from a PyMC3 model of\n",
    "    the posterior distribution that corresponds to the\n",
    "    graphical model in Q.1, using Markov Chain Monte Carlo (MCMC)\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of\n",
    "        the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "    \n",
    "    Outputs: (model, trace)\n",
    "        model is a PyMC3 model object, which represents the graphical model\n",
    "        trace is a PyMC3 trace object, which represents 2000 samples\n",
    "            of everything from the posterior\n",
    "    \"\"\"\n",
    "    # Defines the graphical model\n",
    "    with pm.Model() as model:\n",
    "        # The prior for theta is a Beta distribution with parameters\n",
    "        # alpha and beta, and there's one for each study.\n",
    "        # Make sure to name this parameter 'theta' so so this lab can reference it later. \n",
    "        theta = ...\n",
    "        \n",
    "        # The likelihood for X is binomial, with parameter p=theta,\n",
    "        # observed counts in study_df['X'], and observed N similarly\n",
    "        X = ...\n",
    "        \n",
    "        # Generate samples from the posterior distribution using : run 4\n",
    "        # Markov chains of sampling in parallel, generating 500 samples\n",
    "        # each.\n",
    "        trace = pm.sample(500, chains=4, tune=1000, target_accept=0.95, return_inferencedata=False, progressbar=False)\n",
    "    \n",
    "    return (model, trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is an example of how to run the sampler with fixed values of the hyperparameters alpha and beta. **Note that the output is slightly different from what you saw in lecture: it's a little simpler and easier to work with.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run approximate inference\n",
    "model, trace = approximate_inference_MCMC(10, 20)\n",
    "\n",
    "# Get posterior samples of theta\n",
    "thetas = trace['theta']\n",
    "thetas\n",
    "print(thetas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shape of ``thetas`` is (N x M).  What are N and M, and what does each mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Using the output of PyMC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Generate a histogram of all 2,000 posterior samples for $\\theta_2$ (the SAR for Study 2). Use the `plt.hist` function with `density=True`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2bi\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "How do the samples compare to the two different estimates you saw in Question 1?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2bii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 2.c Compute Posterior Mean Estimates from Samples\n",
    "\n",
    "Fill in the function that computes posterior mean estimates for each $\\theta_i$ for different parameters $\\alpha, \\beta$ of the prior distribution.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_posterior_mean_estimates(alpha_value, beta_value, study_df = study_df):\n",
    "    \"\"\" \n",
    "    Computes posterior mean estimates of theta_i by performing approximate inference\n",
    "    and then sampling from the posterior distribution:\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "        \n",
    "    Output:\n",
    "        posterior_estimates : (num_studies,) 1-D array of the same length as the \n",
    "            number of studies. posterior_estimates[i] contains the \n",
    "            mean estimate for theta_i based on running MCMC\n",
    "    \n",
    "    \"\"\"\n",
    "    ...\n",
    "    posterior_estimates = ...\n",
    "    return posterior_estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d Plot the theoretical distribution of the posterior from Question 1 and the empirical distribution of the posterior from Question 2.\n",
    "\n",
    "Make a 4x3 plot such that each subplot corresponds to a study. \n",
    "\n",
    "Each subplot should contain 2 curves and a frequency histogram:\n",
    "- The PDF of the prior distribution of $\\theta_i$\n",
    "- The PDF of the true posterior distribution $\\theta_i|X_i$ computed in closed form, as in Q.1\n",
    "- The histogram of posterior samples of $\\theta_i|X_i$ computed in Q.2\n",
    "\n",
    "Make sure that you properly label each curve and histogram and give each subplot a meaningful title.\n",
    "\n",
    "To give you a mental image of what we have in mind here is a sample subplot. Don't worry if the colors in yours are different.\n",
    "\n",
    "![](sample_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_densities(alpha_value, beta_value, study_df = study_df): \n",
    "    \"\"\"\n",
    "    Plots for each study the prior distribution, true posterior,\n",
    "    and histogram of posterior samples using MCMC\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "        \n",
    "    Outputs:\n",
    "        fig : Figure with 12 subplots\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(4, 3)\n",
    "    fig.set_figheight(15)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    \n",
    "    theta = np.arange(0, 1.01, 0.01)\n",
    "    prior = beta.pdf(theta, alpha_value, beta_value)\n",
    "    \n",
    "    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df) \n",
    "    samples = trace['theta'] \n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(3):\n",
    "            idx = 3*i+ j\n",
    "            X_i = study_df.loc[idx, 'X']\n",
    "            N_i = study_df.loc[idx, 'N']\n",
    "            study_name = f'Study {idx}'\n",
    "            true_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i) \n",
    "            \n",
    "            ax = axs[i, j]\n",
    "            ax.plot(theta, prior, label = 'Prior')\n",
    "            ax.plot(theta, true_posterior, label = \"Theoretical Posterior\")\n",
    "            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n",
    "            ax.set_title(study_name)\n",
    "            ax.legend()\n",
    "    \n",
    "    plt.tight_layout()        \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting densities for a weak prior\n",
    "fig1 = plot_densities(2, 4, study_df = study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting densities for a strong prior\n",
    "fig2 = plot_densities(20, 40, study_df = study_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "2.d (i) Compare the curve of the theoretical distribution with the histogram of samples from the empirical posterior. Are they similar or different? Explain why.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2di\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "2.d (ii) Compare the two figures corresponding to 'weak' prior $\\theta_i \\sim Beta(2,4)$ and 'strong' prior  $\\theta_i \\sim Beta(20,40)$. How are they different? Explain why.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2dii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.e Approximate Inference for a More Complex Model\n",
    "\n",
    "The previous 2 parts served as a sanity check that the approximate inference techniques used by PyMC3 can approximate the theoretical posterior. The usefulness of such packages becomes apparent when we are dealing with more complex models that don't have conjugacy properties.\n",
    "\n",
    "Consider the following graphical model:\n",
    "\n",
    "![](model_asymptomatic.png)\n",
    "\n",
    "Recent studies have shown that a large fraction of COVID cases do not show symptoms, but all of the studies considered here tested only symptomatic cases. This means that the probability of testing positive (which what we observe) isn't the same as the SAR $\\theta_i$! \n",
    "\n",
    "The estimates of the asymptomatic rate fall in the range $[0.18, 0.43]$. We assume a prior $A\\sim Uniform(0.18, 0.43)$. This means that the probability that a person in a study tests positive is really $\\theta_i*(1-A)$. Hence:\n",
    "\n",
    "$$X_i|\\theta_i, A \\sim Binomial(N_i, \\theta_i\\cdot (1 - A))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "#### Complete the `approximate_inference_asympotmatic_MCMC` function to add dependence on the asymptomatic rate:\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ei\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n",
    "    \"\"\"\n",
    "    Creates and fits a PyMC3 model corresponding to the graphical model above\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "    \n",
    "    Outputs: (model, trace)\n",
    "    \"\"\"\n",
    "    with pm.Model() as model:\n",
    "        theta = ...\n",
    "        A = ...\n",
    "        X = ...\n",
    "        \n",
    "        trace = pm.sample(500, tune=1000, target_accept=0.95, return_inferencedata=False, progressbar=False)\n",
    "    return (model, trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2ei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Notice that the `trace` now contains samples for both `theta` and `A`!\n",
    "\n",
    "Plot a histogram of the posterior estimates for $A$ if $\\alpha=5$ and $\\beta=10$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2eii\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Assuming the model we defined is correct, what can you conclude about the asymptomatic rate $A$ based on the studies and the model?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2eiii\n",
    "manual: true\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('baby_donkey.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  }
 ],
 "metadata": {
  "history": [
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nprint(study_df)",
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "idx": 4,
    "time": "2021-02-08T01:45:21.525Z",
    "type": "execution"
   },
   {
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "time": "2021-02-08T01:45:21.656Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "48852b49462346799b20a02653a3f7ee",
    "idx": 2,
    "time": "2021-02-08T01:45:24.699Z",
    "type": "execution"
   },
   {
    "id": "48852b49462346799b20a02653a3f7ee",
    "time": "2021-02-08T01:45:25.872Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nprint(study_df)",
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "idx": 4,
    "time": "2021-02-08T01:45:26.566Z",
    "type": "execution"
   },
   {
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "time": "2021-02-08T01:45:26.648Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "idx": 4,
    "time": "2021-02-08T01:45:30.742Z",
    "type": "execution"
   },
   {
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "time": "2021-02-08T01:45:30.834Z",
    "type": "completion"
   },
   {
    "code": "# TODO: Complete the function\ndef trivial_theta_estimate(N_value, X_value):\n    \"\"\"\n    Computes the trivial estimate of the Secondary Attack Rate\n    \n    Inputs:\n        N_value : int, number of susceptible individuals\n        X_value : int, number of infected individuals\n        \n    Output:\n        theta_est : float, estimate of probability of infection (SAR)\n    \"\"\"\n    theta_est = X_value / N_value\n    return theta_est",
    "id": "70c92b5478b14c76b745ca302fc2854a",
    "idx": 6,
    "time": "2021-02-08T01:46:05.924Z",
    "type": "execution"
   },
   {
    "id": "70c92b5478b14c76b745ca302fc2854a",
    "time": "2021-02-08T01:46:05.992Z",
    "type": "completion"
   },
   {
    "code": "# Validation tests\nn_test_array = [10, 100, 1000]\nx_test_array = [10, 34, 852]\nres_array = [trivial_theta_estimate(n, x_test_array[i]) for i,n in enumerate(n_test_array)]\nhash_list=['e4c2e8edac362acab7123654b9e73432','149dd5056939405870c9bb50cbc8691c','83659da620f470d5a131b5a9c76cfee7']\nfor i,res in enumerate(res_array):\n    assert get_hash(res) == hash_list[i]\nprint('Test passed!')",
    "id": "627f116799c643978599783de4633210",
    "idx": 7,
    "time": "2021-02-08T01:46:06.276Z",
    "type": "execution"
   },
   {
    "id": "627f116799c643978599783de4633210",
    "time": "2021-02-08T01:46:06.364Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:46:08.777Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:46:08.849Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:46:39.082Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:46:39.154Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)\nstudy_df",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:46:42.922Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:46:43.008Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)\nstudy_df.sort_values('Trivial estimate')",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:56:27.959Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:56:28.045Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "a42f6a40d8f74c198ed28524a6b1fc16",
    "idx": 34,
    "time": "2021-02-08T01:58:15.629Z",
    "type": "execution"
   },
   {
    "id": "a42f6a40d8f74c198ed28524a6b1fc16",
    "time": "2021-02-08T01:58:16.607Z",
    "type": "completion"
   },
   {
    "code": "!conda install m2w64-toolchain",
    "id": "6ecb21aa25c2418a89f224d6c4d1afbf",
    "idx": 35,
    "time": "2021-02-08T02:01:10.488Z",
    "type": "execution"
   },
   {
    "id": "6ecb21aa25c2418a89f224d6c4d1afbf",
    "time": "2021-02-08T02:01:52.977Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        X = pm.Binomial('X', p=theta, observed=study_df['X'], n=study_df['N'])\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "868b271973784e618e5bbe1d9172e216",
    "idx": 36,
    "time": "2021-02-08T02:34:53.853Z",
    "type": "execution"
   },
   {
    "id": "868b271973784e618e5bbe1d9172e216",
    "time": "2021-02-08T02:34:53.947Z",
    "type": "completion"
   },
   {
    "code": "### Hence $\\theta_i|X_i \\sim Beta(\\alpha + X_i, \\beta + N_i - X_i)$\n\n\nThe fact that the posterior probability comes from the same distribution family is known as *conjugacy*. It is a very useful property because it allows us to compute the posteriors in close form.",
    "id": "deca41d2e4b84fec861ac56ded06ec73",
    "idx": 15,
    "time": "2021-02-08T19:05:32.466Z",
    "type": "execution"
   },
   {
    "id": "deca41d2e4b84fec861ac56ded06ec73",
    "time": "2021-02-08T19:05:32.577Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel('Support')\n    plt.title('$\\\\theta_i \\sim Beta(\\\\alpha, \\\\beta)$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:25:25.645Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:25:25.740Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel('Support')\n    plt.title(r'$\\theta_i \\sim Beta(\\alpha, \\beta)$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:25:33.904Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:25:33.991Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:25:35.031Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:25:35.187Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "idx": 2,
    "time": "2021-02-08T19:25:39.740Z",
    "type": "execution"
   },
   {
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "time": "2021-02-08T19:25:41.040Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:25:48.347Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:25:48.883Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0, 1.01, 0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i')\n    plt.ylabel(r'$p(\\theta_i)')\n    plt.title(r'Beta distribution with parameters $\\alpha and $\\beta')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:27:17.114Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:27:17.212Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:27:18.530Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:27:18.894Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0, 1.01, 0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i')\n    plt.ylabel(r'$p(\\theta_i)')\n    plt.title(r'Beta distribution with parameters $\\alpha$ and $\\beta$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:27:26.398Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:27:26.489Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:27:28.387Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:27:28.872Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0, 1.01, 0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.ylabel(r'$p(\\theta_i)$')\n    plt.title(r'Beta distribution with parameters $\\alpha$ and $\\beta$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:27:38.158Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:27:38.250Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:27:38.399Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:27:38.793Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef posterior_mean_estimate(N_value, X_value, alpha_value, beta_value):\n    \"\"\"\n    Computes the posterior E[theta_i|X_i] when we consider a prior theta_i ~ Beta(alpha, beta)\n    \n    Inputs: \n        N_value : int, total number of susceptible individuals\n        X_value : int, number of individuals that became infected\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n    \"\"\"\n    posterior_mean = (alpha_value + X_value)/(alpha_value + beta_value + N_value)\n    return posterior_mean\n    ",
    "id": "cc81886d0ba744f09424be07164de36d",
    "idx": 26,
    "time": "2021-02-08T19:30:35.348Z",
    "type": "execution"
   },
   {
    "id": "cc81886d0ba744f09424be07164de36d",
    "time": "2021-02-08T19:30:35.445Z",
    "type": "completion"
   },
   {
    "code": "# Validation tests\nN_test = 100\nX_test = 20\nalpha_test_array = [1, 10, 100]\nbeta_test_array = [1, 10, 100]\ninputs = list(itertools.product(alpha_test_array, beta_test_array))\nhash_list = ['8ae3cf8f9366cbdea2ccf7706546ba4a','f8ddc3234c0a54e55b01384bcfb23f90','82589ee1f18a2e0b9fe9d14836983102',\n             '08cf5a2033e7e21ec90b6707c24facaf','70da82175ec8a195a3d8b0fa8f69681d','ced20bed08ecfba035cbc3e06657cff2',\n             'c8a7feeaced214c662a999d9bf075e8c','790abc5c38e7c740420b03c24fabb05b','54fbf38cf649866815e0fefc46a1f6c7']\nfor i,inp in enumerate(inputs):\n    assert hash_list[i] == get_hash(posterior_mean_estimate(N_test, X_test, *inp))\nprint('Test passed!')",
    "id": "7e04e7f5526340478eb38b0bacfb5e97",
    "idx": 27,
    "time": "2021-02-08T19:30:36.118Z",
    "type": "execution"
   },
   {
    "id": "7e04e7f5526340478eb38b0bacfb5e97",
    "time": "2021-02-08T19:30:36.206Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='k', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3,  ls=\"--\", color='k', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel('Support')\n    plt.title('Prior $\\\\theta_i \\sim Beta(\\\\alpha={}, \\\\beta={})$'.format(k, 2*k))\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 29,
    "time": "2021-02-08T19:33:23.429Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:33:23.551Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 30,
    "time": "2021-02-08T19:33:27.715Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:33:27.943Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 4,
    "time": "2021-02-08T19:33:33.958Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-08T19:33:34.085Z",
    "type": "completion"
   },
   {
    "code": "# TODO: Complete the function\ndef trivial_theta_estimate(N_value, X_value):\n    \"\"\"\n    Computes the trivial estimate of the Secondary Attack Rate\n    \n    Inputs:\n        N_value : int, number of susceptible individuals\n        X_value : int, number of infected individuals\n        \n    Output:\n        theta_est : float, estimate of probability of infection (SAR)\n    \"\"\"\n    theta_est = X_value / N_value\n    return theta_est",
    "id": "401bb627b4ef4b958b4ec823f8abff47",
    "idx": 6,
    "time": "2021-02-08T19:33:36.113Z",
    "type": "execution"
   },
   {
    "id": "401bb627b4ef4b958b4ec823f8abff47",
    "time": "2021-02-08T19:33:36.203Z",
    "type": "completion"
   },
   {
    "code": "# Validation tests\nn_test_array = [10, 100, 1000]\nx_test_array = [10, 34, 852]\nres_array = [trivial_theta_estimate(n, x_test_array[i]) for i,n in enumerate(n_test_array)]\nhash_list=['e4c2e8edac362acab7123654b9e73432','149dd5056939405870c9bb50cbc8691c','83659da620f470d5a131b5a9c76cfee7']\nfor i,res in enumerate(res_array):\n    assert get_hash(res) == hash_list[i]\nprint('Test passed!')",
    "id": "4c9161d63a544fdb81afcf680ba6d79a",
    "idx": 7,
    "time": "2021-02-08T19:33:36.277Z",
    "type": "execution"
   },
   {
    "id": "4c9161d63a544fdb81afcf680ba6d79a",
    "time": "2021-02-08T19:33:36.372Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 33,
    "time": "2021-02-08T19:37:48.067Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:37:49.164Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='k', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3,  ls=\"--\", color='k', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.title(rf'Prior $\\theta_i \\sim Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 32,
    "time": "2021-02-08T19:39:24.819Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:39:24.916Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 33,
    "time": "2021-02-08T19:39:26.321Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:39:27.398Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3,  ls=\"--\", color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.title(rf'Prior $\\theta_i \\sim Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 32,
    "time": "2021-02-08T19:39:43.150Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:39:43.244Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3, ls=\"--\", color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.title(rf'Prior $\\theta_i \\sim Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 32,
    "time": "2021-02-08T19:39:45.930Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:39:46.021Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 33,
    "time": "2021-02-08T19:39:46.343Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:39:47.483Z",
    "type": "completion"
   },
   {
    "code": "study_df",
    "id": "8f9339ade53a48bfbea36e2a7c247330",
    "idx": 32,
    "time": "2021-02-08T19:41:29.560Z",
    "type": "execution"
   },
   {
    "id": "8f9339ade53a48bfbea36e2a7c247330",
    "time": "2021-02-08T19:41:29.677Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3, ls=\"--\", color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.ylabel(r'$p(\\theta_i)$')\n    plt.title(rf'Prior: $Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 33,
    "time": "2021-02-08T19:43:27.378Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:43:27.483Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 34,
    "time": "2021-02-08T19:43:29.047Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:43:30.103Z",
    "type": "completion"
   },
   {
    "code": "interactive?",
    "id": "993cc627c81343fbb20bd76ccf80b5ae",
    "idx": 34,
    "time": "2021-02-08T19:43:38.208Z",
    "type": "execution"
   },
   {
    "id": "993cc627c81343fbb20bd76ccf80b5ae",
    "time": "2021-02-08T19:43:38.356Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3, color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.ylabel(r'$p(\\theta_i)$')\n    plt.title(rf'Prior: $Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 33,
    "time": "2021-02-08T19:44:39.079Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:44:39.185Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 34,
    "time": "2021-02-08T19:44:39.620Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:44:40.670Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-08T19:50:30.791Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-08T19:50:31.332Z",
    "type": "completion"
   },
   {
    "code": "!pip uninstall Theano Theano-PyMC pymc3  -y\n!pip install 'Theano==1.0.5'\n!pip install 'pymc3==3.11.0'\nimport pymc3",
    "id": "2b050c30ee02497d8fe823b6df8136c3",
    "idx": 45,
    "time": "2021-02-08T19:50:50.744Z",
    "type": "execution"
   },
   {
    "id": "2b050c30ee02497d8fe823b6df8136c3",
    "time": "2021-02-08T19:51:13.549Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "3a5117ca2bd840358e70b83be38ef877",
    "idx": 46,
    "time": "2021-02-08T19:52:21.129Z",
    "type": "execution"
   },
   {
    "id": "3a5117ca2bd840358e70b83be38ef877",
    "time": "2021-02-08T19:52:24.689Z",
    "type": "completion"
   },
   {
    "code": "!pip freeze",
    "id": "fc9502c4c76545c2a568367195cb37b2",
    "idx": 46,
    "time": "2021-02-08T19:52:36.184Z",
    "type": "execution"
   },
   {
    "id": "fc9502c4c76545c2a568367195cb37b2",
    "time": "2021-02-08T19:52:37.866Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-08T19:59:52.511Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-08T19:59:52.614Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a \n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution, tuning\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 46,
    "time": "2021-02-08T20:03:55.725Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-08T20:03:56.277Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 4,
    "time": "2021-02-08T20:04:05.094Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-08T20:04:05.202Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "idx": 2,
    "time": "2021-02-08T20:04:09.493Z",
    "type": "execution"
   },
   {
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "time": "2021-02-08T20:04:09.670Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 4,
    "time": "2021-02-08T20:04:12.482Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-08T20:04:12.624Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a \n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution, tuning\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 46,
    "time": "2021-02-08T20:04:33.106Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-08T20:04:33.201Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(\n    alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the\n    graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of\n        the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a \n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 46,
    "time": "2021-02-08T20:07:39.817Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-08T20:07:39.910Z",
    "type": "completion"
   },
   {
    "code": "m, t = fit_approximate_inference()",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 47,
    "time": "2021-02-08T20:07:47.617Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-08T20:07:47.724Z",
    "type": "completion"
   },
   {
    "code": "m, t = fit_approximate_inference(10, 20)",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 47,
    "time": "2021-02-08T20:08:03.413Z",
    "type": "execution"
   },
   {
    "code": "3",
    "id": "579de7599db744479362e454ea7086c4",
    "idx": 48,
    "time": "2021-02-08T20:08:41.656Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-08T20:08:46.795Z",
    "type": "completion"
   },
   {
    "id": "579de7599db744479362e454ea7086c4",
    "time": "2021-02-08T20:08:46.796Z",
    "type": "completion"
   },
   {
    "code": "m, t = fit_approximate_inference(10, 20)",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 47,
    "time": "2021-02-08T20:09:10.678Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-08T20:11:19.036Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify\ndef sample_posterior_theta(model, trace):\n    \"\"\"\n    Return samples from the posterior distribution theta_i|X_i\n    \n    Inputs:\n        models, trace : PyPM3 objects, outputs of fit_approximate_inference\n        \n    Output:\n        posterior_samples : (2000 x num_studies array), each column contains posterior samples for a theta_i\n    \"\"\"\n    with model:\n        posterior_samples = pm.sample_posterior_predictive(trace, var_names=[\"theta\"], random_seed=0)['theta']\n    return(posterior_samples)   ",
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "idx": 48,
    "time": "2021-02-08T20:11:25.034Z",
    "type": "execution"
   },
   {
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "time": "2021-02-08T20:11:25.136Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify\ndef sample_posterior_theta(model, trace):\n    \"\"\"\n    Return samples from the posterior distribution theta_i|X_i\n    \n    Inputs:\n        models, trace : PyPM3 objects, outputs of fit_approximate_inference\n        \n    Output:\n        posterior_samples : (2000 x num_studies array), each column contains \n            2000 posterior samples for a theta_i\n    \"\"\"\n    with model:\n        posterior_samples = pm.sample_posterior_predictive(\n            trace, var_names=[\"theta\"], random_seed=0\n        )['theta']\n        posterior_theta_samples = posterior_samples['theta']\n    return(posterior_theta_samples)   ",
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "idx": 48,
    "time": "2021-02-08T20:12:39.506Z",
    "type": "execution"
   },
   {
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "time": "2021-02-08T20:12:39.603Z",
    "type": "completion"
   },
   {
    "code": "theta_samples = sample_posterior_theta(m, t)",
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "idx": 49,
    "time": "2021-02-08T20:12:48.357Z",
    "type": "execution"
   },
   {
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "time": "2021-02-08T20:12:48.877Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify\ndef sample_posterior_theta(model, trace):\n    \"\"\"\n    Return samples from the posterior distribution theta_i|X_i\n    \n    Inputs:\n        models, trace : PyPM3 objects, outputs of fit_approximate_inference\n        \n    Output:\n        posterior_samples : (2000 x num_studies array), each column contains \n            2000 posterior samples for a theta_i\n    \"\"\"\n    with model:\n        posterior_samples = pm.sample_posterior_predictive(\n            trace, var_names=[\"theta\"], random_seed=0\n        )\n        posterior_theta_samples = posterior_samples['theta']\n    return(posterior_theta_samples)   ",
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "idx": 48,
    "time": "2021-02-08T20:12:56.931Z",
    "type": "execution"
   },
   {
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "time": "2021-02-08T20:12:57.032Z",
    "type": "completion"
   },
   {
    "code": "theta_samples = sample_posterior_theta(m, t)",
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "idx": 49,
    "time": "2021-02-08T20:12:57.134Z",
    "type": "execution"
   },
   {
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "time": "2021-02-08T20:12:57.418Z",
    "type": "completion"
   },
   {
    "code": "theta_samples",
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "idx": 50,
    "time": "2021-02-08T20:13:00.281Z",
    "type": "execution"
   },
   {
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "time": "2021-02-08T20:13:00.396Z",
    "type": "completion"
   },
   {
    "code": "theta_samples.shape",
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "idx": 50,
    "time": "2021-02-08T20:13:03.420Z",
    "type": "execution"
   },
   {
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "time": "2021-02-08T20:13:03.510Z",
    "type": "completion"
   },
   {
    "code": "pm.sample?",
    "id": "be21c5e4bf4e438e81ac7ae2c5bb4811",
    "idx": 47,
    "time": "2021-02-08T20:13:16.278Z",
    "type": "execution"
   },
   {
    "id": "be21c5e4bf4e438e81ac7ae2c5bb4811",
    "time": "2021-02-08T20:13:16.502Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm\nwith pm.Model() as model:\n    dummy = pm.Beta('dummy', alpha=1, beta=1)\n    pm.sample(1)",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-08T20:14:33.066Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-08T20:15:31.525Z",
    "type": "completion"
   },
   {
    "code": "t",
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "idx": 48,
    "time": "2021-02-08T20:17:16.107Z",
    "type": "execution"
   },
   {
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "time": "2021-02-08T20:17:16.209Z",
    "type": "completion"
   },
   {
    "code": "t['theta']",
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "idx": 48,
    "time": "2021-02-08T20:17:21.216Z",
    "type": "execution"
   },
   {
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "time": "2021-02-08T20:17:21.478Z",
    "type": "completion"
   },
   {
    "code": "t['theta']",
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "idx": 48,
    "time": "2021-02-08T20:17:44.832Z",
    "type": "execution"
   },
   {
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "time": "2021-02-08T20:17:44.921Z",
    "type": "completion"
   },
   {
    "code": "sample_posterior_theta(m, t)",
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "idx": 49,
    "time": "2021-02-08T20:17:51.608Z",
    "type": "execution"
   },
   {
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "time": "2021-02-08T20:17:51.850Z",
    "type": "completion"
   },
   {
    "code": "np.allclose(sample_posterior_theta(m, t), t['theta']",
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "idx": 49,
    "time": "2021-02-08T20:18:01.477Z",
    "type": "execution"
   },
   {
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "time": "2021-02-08T20:18:01.571Z",
    "type": "completion"
   },
   {
    "code": "np.allclose(sample_posterior_theta(m, t), t['theta'])",
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "idx": 49,
    "time": "2021-02-08T20:18:03.681Z",
    "type": "execution"
   },
   {
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "time": "2021-02-08T20:18:03.942Z",
    "type": "completion"
   },
   {
    "code": "# TODO: fill in",
    "id": "22fb656a622640bd8520ad9f2421211f",
    "idx": 51,
    "time": "2021-02-08T20:26:54.269Z",
    "type": "execution"
   },
   {
    "id": "22fb656a622640bd8520ad9f2421211f",
    "time": "2021-02-08T20:26:54.366Z",
    "type": "completion"
   },
   {
    "code": "# Import PyMC3, and create a dummy model so that one-time initialization\n# happens while you're reading over the code in the next cell.\n\n# You can ignore the output of this cell.\n\nimport pymc3 as pm\nwith pm.Model() as model:\n    dummy = pm.Beta('dummy', alpha=1, beta=1)\n    pm.sample(1)",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-09T00:19:23.222Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-09T00:19:35.436Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        AR = pm.Uniform('AR', lower = 0.18, upper = 0.43)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:51:34.807Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:51:34.966Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "idx": 2,
    "time": "2021-02-09T00:51:40.232Z",
    "type": "execution"
   },
   {
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "time": "2021-02-09T00:51:40.407Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 13,
    "time": "2021-02-09T00:51:45.190Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-09T00:51:45.309Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        AR = pm.Uniform('AR', lower = 0.18, upper = 0.43)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:51:49.067Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:51:49.166Z",
    "type": "completion"
   },
   {
    "code": "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)",
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "idx": 77,
    "time": "2021-02-09T00:52:13.708Z",
    "type": "execution"
   },
   {
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "time": "2021-02-09T00:53:03.903Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['AR'])",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:53:16.177Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:53:16.586Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['AR'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:53:32.686Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:53:33.211Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        #theta = # TODO: fill in\n        #A = # TODO: fill in\n        #X = # TODO: fill in\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        A = pm.Uniform('AR', lower = 0.18, upper = 0.43)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        \n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:56:36.221Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:56:36.317Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        #theta = # TODO: fill in\n        #A = # TODO: fill in\n        #X = # TODO: fill in\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        A = pm.Uniform('A', lower = 0.05, upper = 0.73)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        \n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:56:54.389Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:56:54.486Z",
    "type": "completion"
   },
   {
    "code": "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)",
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "idx": 77,
    "time": "2021-02-09T00:56:55.855Z",
    "type": "execution"
   },
   {
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "time": "2021-02-09T00:56:56.860Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['AR'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:56:56.889Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:56:57.360Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        #theta = # TODO: fill in\n        #A = # TODO: fill in\n        #X = # TODO: fill in\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        A = pm.Uniform('A', lower = 0.05, upper = 0.73)\n        X = pm.Binomial('X', p=theta*(1-A), observed=study_df['X'], n=study_df['N'])\n        \n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:57:20.468Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:57:20.563Z",
    "type": "completion"
   },
   {
    "code": "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)",
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "idx": 77,
    "time": "2021-02-09T00:57:21.716Z",
    "type": "execution"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:57:26.582Z",
    "type": "execution"
   },
   {
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "time": "2021-02-09T00:57:36.845Z",
    "type": "completion"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:57:37.266Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:57:49.598Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:57:50.177Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.05, .y3, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:58:00.045Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:58:00.131Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.05, .73, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:58:03.081Z",
    "type": "execution"
   },
   {
    "code": "# TODO: fill in",
    "id": "f7c5a6ee8d044211a7dbb52cf13c2525",
    "idx": 79,
    "time": "2021-02-09T00:58:03.536Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:58:03.615Z",
    "type": "completion"
   },
   {
    "id": "f7c5a6ee8d044211a7dbb52cf13c2525",
    "time": "2021-02-09T00:58:03.683Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n\"\"\"\n    Plots for each study the prior distribution, theoretical posterior \n    and histogram of empirical posterior samples\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            ax = axs[i, j]\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior_y = beta.pdf(x_array, alpha_value+X_i, beta_value+N_i-X_i)\n            ax.plot(x_array, prior_y, label = 'Prior')\n            ax.plot(x_array, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(posterior_theta_samples[:,idx], label = \"Empirical Posterior\", density='True', alpha = 0.5)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:02:09.390Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:02:09.508Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:02:09.562Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:02:09.959Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, theoretical posterior \n    and histogram of empirical posterior samples\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            ax = axs[i, j]\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior_y = beta.pdf(x_array, alpha_value+X_i, beta_value+N_i-X_i)\n            ax.plot(x_array, prior_y, label = 'Prior')\n            ax.plot(x_array, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(posterior_theta_samples[:,idx], label = \"Empirical Posterior\", density='True', alpha = 0.5)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:02:23.636Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:02:23.996Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = fit_approximate_inference(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:05:03.052Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:05:03.148Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:05:03.809Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:05:06.520Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:06:24.240Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:06:24.342Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:06:24.580Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:06:27.461Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef approximate_inference_MCMC(\n    alpha_value, beta_value, study_df = study_df\n):\n    \"\"\"\n    Creates and generates samples from a PyMC3 model of\n    the posterior distribution that corresponds to the\n    graphical model in Q.1, using Markov Chain Monte Carlo (MCMC)\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of\n        the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a PyMC3 model object, which represents the graphical model\n        trace is a PyMC3 trace object, which represents 2000 samples\n            of everything from the posterior\n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution using : run 4\n        # Markov chains of sampling in parallel, generating 500 samples\n        # each.\n        trace = pm.sample(500, chains=4, tune=1000, target_accept=0.95)\n    \n    return (model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 55,
    "time": "2021-02-09T01:06:32.712Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-09T01:06:32.806Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:06:35.842Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:06:35.939Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:06:38.627Z",
    "type": "execution"
   },
   {
    "code": "# Plot the resulting densities for a strong prior\nfig2 = plot_densities(20, 40, study_df = study_df)",
    "id": "21069a4809fb46408f18c362be53a79d",
    "idx": 68,
    "time": "2021-02-09T01:06:45.412Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:06:56.288Z",
    "type": "completion"
   },
   {
    "id": "21069a4809fb46408f18c362be53a79d",
    "time": "2021-02-09T01:06:56.290Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            true_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, true_posterior, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:07:26.519Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:07:26.623Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:07:26.736Z",
    "type": "execution"
   },
   {
    "code": "# Plot the resulting densities for a strong prior\nfig2 = plot_densities(20, 40, study_df = study_df)",
    "id": "21069a4809fb46408f18c362be53a79d",
    "idx": 68,
    "time": "2021-02-09T01:07:28.251Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:07:42.748Z",
    "type": "completion"
   },
   {
    "id": "21069a4809fb46408f18c362be53a79d",
    "time": "2021-02-09T01:07:57.595Z",
    "type": "completion"
   },
   {
    "code": "# Run approximate inference\nmodel, trace = approximate_inference_MCMC(10, 20)\n\n# Get posterior samples of theta\nthetas = trace['theta']\nthetas",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 64,
    "time": "2021-02-09T01:14:33.260Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-09T01:14:42.877Z",
    "type": "completion"
   },
   {
    "code": "# TODO: fill in\nplt.hist(thetas[:, 2], density=True)",
    "id": "91ecf69958934aa48328f4c97a8f7042",
    "idx": 67,
    "time": "2021-02-09T01:14:44.946Z",
    "type": "execution"
   },
   {
    "id": "91ecf69958934aa48328f4c97a8f7042",
    "time": "2021-02-09T01:14:45.272Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pymc_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fdab57f3c2effd3a24a84ba5d55def8fb299808cd0e14995f96a5d9a8f4f653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
