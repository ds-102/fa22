{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0:  Review and warm-up\n",
    "Welcome to the first Data 102 lab! \n",
    "\n",
    "The goal of this lab is to review some basic probability and programming. We will also learn more about binary decision making.\n",
    "\n",
    "The code (and answers) that you need to write is commented out with a message **\"TODO: ...\"**. There is additional documentation for each part as you go along.\n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "## Submission\n",
    "To submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Tuesday, August 30, 2022 at 11:59 PM. PST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Let's begin by importing the libraries we will use. You can find the documentation for the libraries here:\n",
    "* matplotlib: https://matplotlib.org/3.1.1/contents.html\n",
    "* numpy: https://docs.scipy.org/doc/\n",
    "* pandas: https://pandas.pydata.org/pandas-docs/stable/\n",
    "* seaborn: https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import timeit\n",
    "import hashlib\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def get_hash(num):  # <- helper function for assessing correctness\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 0: Vectorized operations in NumPy\n",
    "\n",
    "We'll start this lab by reviewing the concept of **vectorization**. Many of the functions in NumPy (and pandas) are optimized to be much faster than the equivalent code using a `for` loop. This is because NumPy uses optimized and pre-compiled code written in a low-level language (in this case, C) to carry out mathematical operations. By using NumPy's vectorized operations instead of iterating explicitly (e.g., writing `for` loops), we can make our code run much faster. In some cases, this difference is small, but you'll see in future labs and homework assignments that sometimes it has a big impact.\n",
    "\n",
    "Let's see vectorization in action and measure the time it takes to perform some vectorized and non-vectorized tasks on NumPy arrays. We'll start by summing numbers from 0 to 14,999. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "sum_nonvect = 0\n",
    "for item in range(0, 15000):\n",
    "     sum_nonvect += item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "sum_vect = np.sum(np.arange(15000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) How much faster is the vectorized version? Your answer should be a multiplicative factor (e.g., \"it takes half as long\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO: YOUR ANSWER HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, consider the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0, 60, 3).reshape(4, 5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to compute a new array where each entry is the average of two neighboring entries in the original array. So, the first row would look like `[1.5, 4.5, 7.5, 10.5]` (we'll see examples of operations like this later in the class). Let's try doing this two different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Using nested for loops\n",
    "\n",
    "new_array_slow = np.zeros([arr.shape[0], arr.shape[1] - 1])\n",
    "for i in range(arr.shape[0]):\n",
    "    for j in range (arr.shape[1] - 1):\n",
    "        new_array_slow[i,j] = (arr[i,j] + arr[i, j+1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "new_array_fast = (arr[:, :-1] + arr[:, 1:])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Suppose your friend looks at this and says that while the vectorized version does run faster, both versions run fast enough that it doesn't matter. Give two reasons your friend might be wrong.\n",
    "\n",
    "*Hint: What happens if an algorithm needs to run this kind of operation many times?*\n",
    "\n",
    "*Hint: try replacing `arr` with `np.random.random([2000, 2000])`. How do the results change?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO: your answers here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: The sinking of the Titanic\n",
    "On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg. Unfortunately, there werenâ€™t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew. \n",
    "\n",
    "In this question we will work with data about passengers traveling on the Titanic, and we will try to understand whether some groups of people were more likely to survive than others. We will also fit a binary classifier to the data and check its performance (e.g. how many false positive does it produce?) \n",
    "\n",
    "Let's start by importing the Titanic dataset using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"titanic.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief description of the variables included in the dataframe:\n",
    "* **Survived**: binary variable taking value 1 if the person survived the shipwreck, 0 otherwise;\n",
    "* **Pclass**: whether the passenger was traveling in 1st, 2nd, or 3rd class; \n",
    "* **Name**: passenger's name;\n",
    "* **Sex**: passenger's gender;\n",
    "* **Age**: passenger's age;\n",
    "* **Siblings/Spouses Aboard**: how many siblings or spouses the passenger is traveling with;\n",
    "* **Parents/Children Aboard**: how many parents or children the passenger is traveling with;\n",
    "* **Fare**: what was the fare that the passenger paid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.a: Dataset check\n",
    "We will first check some general properties of the dataframe. For example, we will see how many rows and columns the dataframe has and if there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find the number of rows and columns in the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how many missing values there are per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell below, we can also check how many different values each variable takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.b: Exploring the dataset\n",
    "We'll now look into more detail at some descriptive statistics and plots. We would like to know what is the percentage of people who survived the shipwreck and what is the passengers' distribution in terms of sex, age, class, etc.\n",
    "\n",
    "For a refresher on data visualization using pandas and seaborn, you can refer to [Chapter 10 of the Data 100 textbook](https://www.textbook.ds100.org/ch/11/viz_intro.html).\n",
    "\n",
    "Let's start by computing the percentage of people in the dataset who survived the shipwreck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the percentage of people who survived (expressed as a decimal between 0 and 1)\n",
    "survival_prob = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: do not modify!\n",
    "assert(get_hash(survival_prob)== '4fe6b7a204127acbec520ac2997133dc')\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below uses the `countplot` function from seaborn to generate a plot displaying how many passengers were traveling in each of the three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = titanic[\"Pclass\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distribution is not uniform, and that the majority of the passengers were traveling in third class. \n",
    "\n",
    "In the next question, write a line of code to generate a bar graph for the distribution of passenger sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use countplot to show how the distribution of passenger sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use countplot to show the distribution of the number of parents/children aboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up: there were nearly twice as many male passengers as female passengers, and the majority of people were traveling alone.\n",
    "\n",
    "Let's conclude by looking at the distribution of age and fare paid. In the next cell, write a line of code to visualize the distribution of passenger ages. *Hint: since the age column contains numerical data, you shouldn't use `sns.countplot`, which is meant for categorical data. Is there another seaborn function you can use?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the distribution of passenger ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that most travelers were in their 20s and 30s, and there were also many babies. What is the age of the youngest passenger? And the oldest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min(titanic[\"Age\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the age of the oldest passenger \n",
    "max_age = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: do not modify!\n",
    "assert(get_hash(max_age) == '8ee5d21b272d43a875504f3e5845e141')\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use displot to show the fare distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fare distribution is really skewed: most people spent very little, but there is someone who spent even more than 500! Who are these people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: display the rows corresponding to passengers who spent more than 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.c: Conditional probabilites\n",
    "\n",
    "So far, we have looked at the variables separately, considering each marginal distribution. This tells us about them individually, but we're also interested in the relationships between variables. In particular, we want to find connections between survival and the other variables. For example, we might wonder whether people in first class had a higher probability of surviving than people in third class or if females survived more or less often than males. To answer this type of question, we'll need to look at **conditional probabilities**. For a refresher on conditional probabilities, you can refer to [Section 4.4 of the Data 140 textbook](http://prob140.org/textbook/content/Chapter_04/04_Conditional_Distributions.html).\n",
    "\n",
    "Let's start by looking at the conditional probabilities of survival given class type. If we denote the survival variable by $S$ and the class variable by $C$, we are comparing:\n",
    "\n",
    "$$\\mathbb{P}(S = 1 | C = 1) \\quad \\text{ vs } \\quad \\mathbb{P}(S = 1 | C = 2) \\quad \\text{ vs }\\quad \\mathbb{P}(S = 1 | C = 3)$$\n",
    "\n",
    "We'll first compute $\\mathbb{P}(S = 1 | C = 1)$, the probability of surviving given that the passenger has a first-class ticket. To do so, remember the definition of conditional probability: for two events $A$ and $B$,\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A \\text{ and } B)}{P(B)}\n",
    "$$\n",
    "\n",
    "In this case, we don't have to use Bayes' rule since we can compute the conditional probably directly using the definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the following code to compute P(S=1|C=1)\n",
    "firstclass_survival_prob = np.mean((titanic[\"Survived\"] == ...) & (titanic[\"Pclass\"] == ...)) / np.mean(titanic[\"Pclass\"] == ...)\n",
    "firstclass_survival_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: do not modify!\n",
    "assert get_hash(np.round(firstclass_survival_prob, 2)) == 'b9c48c2d04160ef1ff72dba569292058'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, almost 63% of passengers traveling in first class survived: not bad! \n",
    "\n",
    "What about people in the other two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the conditional probability of survival given that the passenger is in class 2\n",
    "secondclass_survival_prob = ...\n",
    "secondclass_survival_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: do not modify!\n",
    "assert get_hash(np.round(secondclass_survival_prob, 2)) == '7a7763d4618eb5666515c04dd53a3c08'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the conditional probability of survival given that the passenger is in class 3\n",
    "thirdclass_survival_prob = ...\n",
    "thirdclass_survival_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: do not modify!\n",
    "assert get_hash(np.round(thirdclass_survival_prob, 2)) == '5d6182b8169f820c3e247e91131138ea'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survival probabilities were very different for the three class types! High class passenger had higher chances to survive.\n",
    "\n",
    "We can also visualize survivals by class running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Pclass', hue = \"Survived\", data = titanic);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can keep on exploring and play with the other variables too, checking if there are groups with high or low probability of surviving. Try to condition on more than one variable (e.g. condition on both class type and gender)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.d: Binary classification\n",
    "\n",
    "In this last part, we're going to use logistic regression to predict passenger survival from the other variables. Here are the steps we'll follow:\n",
    "\n",
    "1. Split the dataset into a training and test set\n",
    "2. Fit a logistic regression model to the training set\n",
    "3. Evaluate the performance on the test set using the language of binary decision-making that you saw in last week's lecture\n",
    "\n",
    "We've done most of steps 1 and 2 for you, but we **strongly** encourage you to read through and understand all the code, since you'll need to do it yourself in future labs and homework assignments. Some resources that might be helpful:\n",
    "\n",
    "* [Data 100 textbook: logistic regression](https://www.textbook.ds100.org/ch/19/classification_log_reg.html)\n",
    "* [Data 100 textbook: one-hot encoding](https://www.textbook.ds100.org/ch/15/linear_feature_eng.html)\n",
    "* scikit-learn's documentation for `LabelEncoder` and `train_test_split` (you'll have to find these on your own).\n",
    "\n",
    "\n",
    "Running the following cell will prepare the data and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Sex\"] = LabelEncoder().fit_transform(titanic[\"Sex\"]) # encode gender variable (from string to integer)\n",
    "titanic = titanic.drop(\"Name\", axis = 1) # drop Name column\n",
    "\n",
    "X = titanic.drop(\"Survived\", axis = 1) # independent variables\n",
    "y = titanic[\"Survived\"] # dependent variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to fit our logistic regression classifier and to predict which passengers in the test data survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(X_train, y_train) # fit the classifier to the training data\n",
    "yhat = lr.predict(X_test) # predict survival for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in the following cell to generate a new dataframe with two columns: the first containing our **decisions** and the second containing the values in **reality**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output[\"Decisions\"] = ...\n",
    "output[\"Reality\"] = y_test.values\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation test: do not modify\n",
    "assert get_hash(output['Decisions'].sum()) == 'e2ef524fbf3d9fe611d5a8e90fefdc9c'\n",
    "assert get_hash((output['Decisions'] & output['Reality']).sum()) == 'ad61ab143223efbc24c7d2583be69251'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now interested in evaluating the performance of the logistic regression classifier: let's check how many false positive, false negative, true positive and true negative we have obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the number of false positives (FP), false negatives (FN), true positives (TP), and true negatives (TN)\n",
    "FP = ...\n",
    "FN = ...\n",
    "TP = ...\n",
    "TN = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation test: do not modify\n",
    "performance = [FP, FN, TP, TN]\n",
    "hash_list = ['37693cfc748049e45d87b8c7d8b9aacd', \n",
    "             '6364d3f0f495b6ab9dcf8d3b5c6e0b01', \n",
    "             'ad61ab143223efbc24c7d2583be69251', \n",
    "             '013d407166ec4fa56eb1e1f8cbe183b9']\n",
    "assert all([get_hash(num) == hash_list[i] for (i, num) in enumerate(performance)])\n",
    "print(\"Test passed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the four numbers you found above, answer the two multiple choice questions below. *Hint: It might help to draw out the 2-by-2 table as in lecture.*\n",
    "\n",
    "In which of the following two settings did the classifier perform better?\n",
    "\n",
    "(a) People who actually survived\n",
    "\n",
    "(b) People who actually did not survive\n",
    "\n",
    "\n",
    "In which of the following two settings did the classifier perform better?\n",
    "\n",
    "(a) People for whom the classifier predicted they survived\n",
    "\n",
    "(b) People for whom the classifier predicted they did not survive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TO DO: your answers here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests\n",
    "If all the tests below pass, you can assume you have successfuly completed the testable parts of the lab. Don't worry about understanding the code below; just make sure no asserts fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tests = [survival_prob, max_age, np.round(firstclass_survival_prob, 2), \n",
    "         np.round(secondclass_survival_prob, 2), np.round(thirdclass_survival_prob, 2),\n",
    "         output['Decisions'].sum(), (output['Decisions'] & output['Reality']).sum(),\n",
    "         FP, FN, TP, TN]\n",
    "hash_list = ['4fe6b7a204127acbec520ac2997133dc', \n",
    "            '8ee5d21b272d43a875504f3e5845e141',\n",
    "            'b9c48c2d04160ef1ff72dba569292058',\n",
    "            '7a7763d4618eb5666515c04dd53a3c08', \n",
    "            '5d6182b8169f820c3e247e91131138ea',\n",
    "            'e2ef524fbf3d9fe611d5a8e90fefdc9c',\n",
    "            'ad61ab143223efbc24c7d2583be69251',\n",
    "            '37693cfc748049e45d87b8c7d8b9aacd', \n",
    "            '6364d3f0f495b6ab9dcf8d3b5c6e0b01', \n",
    "            'ad61ab143223efbc24c7d2583be69251', \n",
    "            '013d407166ec4fa56eb1e1f8cbe183b9']\n",
    "assert all([get_hash(t) == hash_list[i] for (i, t) in enumerate(tests)])\n",
    "print(\"All tests passed! You are awesome!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('cute_quokka.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print('Congrats! You made it to the end of the lab!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
